{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "obvious-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distant-textbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PassengerId  Survived  Pclass  \\\n",
       "0             1         0       3   \n",
       "1             2         1       1   \n",
       "2             3         1       3   \n",
       "3             4         1       1   \n",
       "4             5         0       3   \n",
       "5             6         0       3   \n",
       "6             7         0       1   \n",
       "7             8         0       3   \n",
       "8             9         1       3   \n",
       "9            10         1       2   \n",
       "10           11         1       3   \n",
       "11           12         1       1   \n",
       "12           13         0       3   \n",
       "13           14         0       3   \n",
       "14           15         0       3   \n",
       "\n",
       "                                                 Name     Sex   Age  SibSp  \\\n",
       "0                             Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1   Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                              Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3        Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                            Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                    Moran, Mr. James    male   NaN      0   \n",
       "6                             McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                      Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8   Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                 Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                    Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                           Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                     Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                        Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14               Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "\n",
       "    Parch            Ticket     Fare Cabin Embarked  \n",
       "0       0         A/5 21171   7.2500   NaN        S  \n",
       "1       0          PC 17599  71.2833   C85        C  \n",
       "2       0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3       0            113803  53.1000  C123        S  \n",
       "4       0            373450   8.0500   NaN        S  \n",
       "5       0            330877   8.4583   NaN        Q  \n",
       "6       0             17463  51.8625   E46        S  \n",
       "7       1            349909  21.0750   NaN        S  \n",
       "8       2            347742  11.1333   NaN        S  \n",
       "9       0            237736  30.0708   NaN        C  \n",
       "10      1           PP 9549  16.7000    G6        S  \n",
       "11      0            113783  26.5500  C103        S  \n",
       "12      0         A/5. 2151   8.0500   NaN        S  \n",
       "13      5            347082  31.2750   NaN        S  \n",
       "14      0            350406   7.8542   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titan_train = pd.read_csv('../../Dataset/Titanic/train.csv')\n",
    "titan_test = pd.read_csv('../../Dataset/Titanic/test.csv')\n",
    "titan_train.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rural-notion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = titan_train['Survived'].value_counts().plot(kind='bar', figsize=(12, 8))\n",
    "ax.set_xlabel(xlabel='Survived')\n",
    "ax.set_ylabel(ylabel='sum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fatal-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = titan_train['Age'].plot.hist()\n",
    "ax.set_xlabel('age')\n",
    "ax.set_ylabel('number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "married-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'density')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = titan_train.query('Survived == 0')['Age'].plot.density()\n",
    "titan_train.query('Survived == 1')['Age'].plot.density()\n",
    "ax.legend(['Survived == 1', 'Survived == 0'])\n",
    "ax.set_xlabel('age')\n",
    "ax.set_ylabel('density')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "closed-ghost",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape = (891, 15)\n",
      "x_test.shape = (418, 15)\n"
     ]
    }
   ],
   "source": [
    "def preprocessing(dfdata):\n",
    "\n",
    "    dfresult= pd.DataFrame()\n",
    "\n",
    "    #Pclass\n",
    "    dfPclass = pd.get_dummies(dfdata['Pclass'])\n",
    "    dfPclass.columns = ['Pclass_' +str(x) for x in dfPclass.columns ]\n",
    "    dfresult = pd.concat([dfresult,dfPclass],axis = 1)\n",
    "\n",
    "    #Sex\n",
    "    dfSex = pd.get_dummies(dfdata['Sex'])\n",
    "    dfresult = pd.concat([dfresult,dfSex],axis = 1)\n",
    "\n",
    "    #Age\n",
    "    dfresult['Age'] = dfdata['Age'].fillna(0)\n",
    "    dfresult['Age_null'] = pd.isna(dfdata['Age']).astype('int32')\n",
    "\n",
    "    #SibSp,Parch,Fare\n",
    "    dfresult['SibSp'] = dfdata['SibSp']\n",
    "    dfresult['Parch'] = dfdata['Parch']\n",
    "    dfresult['Fare'] = dfdata['Fare']\n",
    "\n",
    "    #Carbin\n",
    "    dfresult['Cabin_null'] =  pd.isna(dfdata['Cabin']).astype('int32')\n",
    "\n",
    "    #Embarked\n",
    "    dfEmbarked = pd.get_dummies(dfdata['Embarked'],dummy_na=True)\n",
    "    dfEmbarked.columns = ['Embarked_' + str(x) for x in dfEmbarked.columns]\n",
    "    dfresult = pd.concat([dfresult,dfEmbarked],axis = 1)\n",
    "\n",
    "    return(dfresult)\n",
    "\n",
    "x_train = preprocessing(titan_train)\n",
    "y_train = titan_train['Survived'].values\n",
    "\n",
    "x_test = preprocessing(titan_test)\n",
    "# y_test = titan_test['Survived'].values\n",
    "\n",
    "print(\"x_train.shape =\", x_train.shape )\n",
    "print(\"x_test.shape =\", x_test.shape )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mineral-explosion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 20)                320       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 541\n",
      "Trainable params: 541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Sequential \n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(15, )))\n",
    "model.add(layers.Dense(10, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "verbal-blackberry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "WARNING:tensorflow:From /home/lewin/anaconda3/envs/tf-gpu2.2/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.9570 - auc: 0.5858 - val_loss: 1.2879 - val_auc: 0.6607\n",
      "Epoch 2/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.3088 - auc: 0.5596 - val_loss: 0.9514 - val_auc: 0.6473\n",
      "Epoch 3/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 1.0074 - auc: 0.5798 - val_loss: 0.7860 - val_auc: 0.6811\n",
      "Epoch 4/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.8886 - auc: 0.6012 - val_loss: 0.7010 - val_auc: 0.7032\n",
      "Epoch 5/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.8321 - auc: 0.6248 - val_loss: 0.6583 - val_auc: 0.7240\n",
      "Epoch 6/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7974 - auc: 0.6280 - val_loss: 0.6520 - val_auc: 0.7092\n",
      "Epoch 7/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7693 - auc: 0.6314 - val_loss: 0.6256 - val_auc: 0.7194\n",
      "Epoch 8/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.7425 - auc: 0.6432 - val_loss: 0.6043 - val_auc: 0.7301\n",
      "Epoch 9/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7207 - auc: 0.6507 - val_loss: 0.5936 - val_auc: 0.7276\n",
      "Epoch 10/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.7014 - auc: 0.6613 - val_loss: 0.5799 - val_auc: 0.7380\n",
      "Epoch 11/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6859 - auc: 0.6620 - val_loss: 0.5753 - val_auc: 0.7391\n",
      "Epoch 12/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6714 - auc: 0.6731 - val_loss: 0.5664 - val_auc: 0.7531\n",
      "Epoch 13/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6560 - auc: 0.6726 - val_loss: 0.5711 - val_auc: 0.7362\n",
      "Epoch 14/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6497 - auc: 0.6754 - val_loss: 0.5549 - val_auc: 0.7529\n",
      "Epoch 15/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6383 - auc: 0.6919 - val_loss: 0.5455 - val_auc: 0.7696\n",
      "Epoch 16/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6268 - auc: 0.6970 - val_loss: 0.5470 - val_auc: 0.7689\n",
      "Epoch 17/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6202 - auc: 0.7000 - val_loss: 0.5421 - val_auc: 0.7734\n",
      "Epoch 18/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6124 - auc: 0.7092 - val_loss: 0.5342 - val_auc: 0.7814\n",
      "Epoch 19/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6074 - auc: 0.7192 - val_loss: 0.5312 - val_auc: 0.7873\n",
      "Epoch 20/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.6032 - auc: 0.7172 - val_loss: 0.5456 - val_auc: 0.7738\n",
      "Epoch 21/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5940 - auc: 0.7306 - val_loss: 0.5245 - val_auc: 0.8025\n",
      "Epoch 22/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5918 - auc: 0.7402 - val_loss: 0.5210 - val_auc: 0.8024\n",
      "Epoch 23/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5839 - auc: 0.7470 - val_loss: 0.5214 - val_auc: 0.8062\n",
      "Epoch 24/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5810 - auc: 0.7508 - val_loss: 0.5185 - val_auc: 0.8080\n",
      "Epoch 25/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5764 - auc: 0.7569 - val_loss: 0.5153 - val_auc: 0.8086\n",
      "Epoch 26/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.5718 - auc: 0.7624 - val_loss: 0.5157 - val_auc: 0.8146\n",
      "Epoch 27/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5688 - auc: 0.7672 - val_loss: 0.5111 - val_auc: 0.8164\n",
      "Epoch 28/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5664 - auc: 0.7685 - val_loss: 0.5099 - val_auc: 0.8200\n",
      "Epoch 29/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5618 - auc: 0.7783 - val_loss: 0.5116 - val_auc: 0.8308\n",
      "Epoch 30/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5613 - auc: 0.7822 - val_loss: 0.5104 - val_auc: 0.8317\n",
      "Epoch 31/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5646 - auc: 0.7883 - val_loss: 0.5182 - val_auc: 0.8310\n",
      "Epoch 32/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5551 - auc: 0.7925 - val_loss: 0.5034 - val_auc: 0.8312\n",
      "Epoch 33/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5519 - auc: 0.7941 - val_loss: 0.5043 - val_auc: 0.8391\n",
      "Epoch 34/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5486 - auc: 0.7978 - val_loss: 0.5011 - val_auc: 0.8414\n",
      "Epoch 35/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5452 - auc: 0.7998 - val_loss: 0.4992 - val_auc: 0.8445\n",
      "Epoch 36/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5429 - auc: 0.8025 - val_loss: 0.4967 - val_auc: 0.8474\n",
      "Epoch 37/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5406 - auc: 0.8053 - val_loss: 0.4946 - val_auc: 0.8485\n",
      "Epoch 38/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5375 - auc: 0.8076 - val_loss: 0.4974 - val_auc: 0.8485\n",
      "Epoch 39/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5351 - auc: 0.8127 - val_loss: 0.4916 - val_auc: 0.8484\n",
      "Epoch 40/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5322 - auc: 0.8087 - val_loss: 0.4872 - val_auc: 0.8467\n",
      "Epoch 41/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5295 - auc: 0.8110 - val_loss: 0.4924 - val_auc: 0.8514\n",
      "Epoch 42/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5265 - auc: 0.8173 - val_loss: 0.4865 - val_auc: 0.8539\n",
      "Epoch 43/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5234 - auc: 0.8186 - val_loss: 0.4833 - val_auc: 0.8543\n",
      "Epoch 44/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5212 - auc: 0.8170 - val_loss: 0.4788 - val_auc: 0.8552\n",
      "Epoch 45/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5194 - auc: 0.8230 - val_loss: 0.4718 - val_auc: 0.8577\n",
      "Epoch 46/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5134 - auc: 0.8242 - val_loss: 0.4674 - val_auc: 0.8580\n",
      "Epoch 47/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5107 - auc: 0.8227 - val_loss: 0.4620 - val_auc: 0.8615\n",
      "Epoch 48/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5076 - auc: 0.8296 - val_loss: 0.4610 - val_auc: 0.8637\n",
      "Epoch 49/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5104 - auc: 0.8252 - val_loss: 0.4597 - val_auc: 0.8638\n",
      "Epoch 50/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5076 - auc: 0.8366 - val_loss: 0.4658 - val_auc: 0.8598\n",
      "Epoch 51/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5085 - auc: 0.8249 - val_loss: 0.4455 - val_auc: 0.8666\n",
      "Epoch 52/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.5004 - auc: 0.8367 - val_loss: 0.4675 - val_auc: 0.8687\n",
      "Epoch 53/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4982 - auc: 0.8369 - val_loss: 0.4477 - val_auc: 0.8729\n",
      "Epoch 54/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4941 - auc: 0.8386 - val_loss: 0.4528 - val_auc: 0.8719\n",
      "Epoch 55/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4896 - auc: 0.8475 - val_loss: 0.4475 - val_auc: 0.8738\n",
      "Epoch 56/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4870 - auc: 0.8442 - val_loss: 0.4481 - val_auc: 0.8713\n",
      "Epoch 57/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4884 - auc: 0.8430 - val_loss: 0.4466 - val_auc: 0.8718\n",
      "Epoch 58/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4840 - auc: 0.8427 - val_loss: 0.4403 - val_auc: 0.8722\n",
      "Epoch 59/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4818 - auc: 0.8468 - val_loss: 0.4480 - val_auc: 0.8737\n",
      "Epoch 60/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4852 - auc: 0.8462 - val_loss: 0.4342 - val_auc: 0.8728\n",
      "Epoch 61/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4797 - auc: 0.8424 - val_loss: 0.4378 - val_auc: 0.8770\n",
      "Epoch 62/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4816 - auc: 0.8509 - val_loss: 0.4383 - val_auc: 0.8789\n",
      "Epoch 63/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4814 - auc: 0.8444 - val_loss: 0.4383 - val_auc: 0.8791\n",
      "Epoch 64/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4774 - auc: 0.8556 - val_loss: 0.4461 - val_auc: 0.8769\n",
      "Epoch 65/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4775 - auc: 0.8464 - val_loss: 0.4240 - val_auc: 0.8779\n",
      "Epoch 66/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4769 - auc: 0.8460 - val_loss: 0.4234 - val_auc: 0.8745\n",
      "Epoch 67/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4723 - auc: 0.8481 - val_loss: 0.4258 - val_auc: 0.8764\n",
      "Epoch 68/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4693 - auc: 0.8546 - val_loss: 0.4252 - val_auc: 0.8757\n",
      "Epoch 69/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4658 - auc: 0.8520 - val_loss: 0.4203 - val_auc: 0.8766\n",
      "Epoch 70/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4653 - auc: 0.8548 - val_loss: 0.4222 - val_auc: 0.8772\n",
      "Epoch 71/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4631 - auc: 0.8565 - val_loss: 0.4187 - val_auc: 0.8768\n",
      "Epoch 72/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4709 - auc: 0.8471 - val_loss: 0.4146 - val_auc: 0.8739\n",
      "Epoch 73/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4603 - auc: 0.8601 - val_loss: 0.4299 - val_auc: 0.8757\n",
      "Epoch 74/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4587 - auc: 0.8603 - val_loss: 0.4151 - val_auc: 0.8764\n",
      "Epoch 75/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4592 - auc: 0.8573 - val_loss: 0.4219 - val_auc: 0.8807\n",
      "Epoch 76/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4563 - auc: 0.8600 - val_loss: 0.4121 - val_auc: 0.8790\n",
      "Epoch 77/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4559 - auc: 0.8574 - val_loss: 0.4131 - val_auc: 0.8791\n",
      "Epoch 78/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4528 - auc: 0.8614 - val_loss: 0.4179 - val_auc: 0.8790\n",
      "Epoch 79/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4549 - auc: 0.8610 - val_loss: 0.4229 - val_auc: 0.8811\n",
      "Epoch 80/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4604 - auc: 0.8570 - val_loss: 0.4071 - val_auc: 0.8804\n",
      "Epoch 81/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4642 - auc: 0.8525 - val_loss: 0.4049 - val_auc: 0.8775\n",
      "Epoch 82/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4580 - auc: 0.8571 - val_loss: 0.4211 - val_auc: 0.8810\n",
      "Epoch 83/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4512 - auc: 0.8632 - val_loss: 0.4063 - val_auc: 0.8851\n",
      "Epoch 84/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4529 - auc: 0.8632 - val_loss: 0.4124 - val_auc: 0.8848\n",
      "Epoch 85/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4552 - auc: 0.8571 - val_loss: 0.4040 - val_auc: 0.8891\n",
      "Epoch 86/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4481 - auc: 0.8663 - val_loss: 0.4156 - val_auc: 0.8858\n",
      "Epoch 87/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4458 - auc: 0.8668 - val_loss: 0.4050 - val_auc: 0.8883\n",
      "Epoch 88/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4465 - auc: 0.8651 - val_loss: 0.4056 - val_auc: 0.8887\n",
      "Epoch 89/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4473 - auc: 0.8633 - val_loss: 0.4061 - val_auc: 0.8876\n",
      "Epoch 90/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4494 - auc: 0.8629 - val_loss: 0.4009 - val_auc: 0.8901\n",
      "Epoch 91/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4429 - auc: 0.8654 - val_loss: 0.4096 - val_auc: 0.8876\n",
      "Epoch 92/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4455 - auc: 0.8657 - val_loss: 0.4001 - val_auc: 0.8895\n",
      "Epoch 93/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4440 - auc: 0.8652 - val_loss: 0.3987 - val_auc: 0.8891\n",
      "Epoch 94/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4437 - auc: 0.8642 - val_loss: 0.4032 - val_auc: 0.8925\n",
      "Epoch 95/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4428 - auc: 0.8645 - val_loss: 0.3982 - val_auc: 0.8915\n",
      "Epoch 96/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - auc: 0.8693 - val_loss: 0.4066 - val_auc: 0.8844\n",
      "Epoch 97/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4410 - auc: 0.8657 - val_loss: 0.3942 - val_auc: 0.8898\n",
      "Epoch 98/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4374 - auc: 0.8695 - val_loss: 0.3970 - val_auc: 0.8903\n",
      "Epoch 99/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4368 - auc: 0.8695 - val_loss: 0.3952 - val_auc: 0.8893\n",
      "Epoch 100/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4372 - auc: 0.8689 - val_loss: 0.3966 - val_auc: 0.8885\n",
      "Epoch 101/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4369 - auc: 0.8688 - val_loss: 0.3923 - val_auc: 0.8881\n",
      "Epoch 102/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4368 - auc: 0.8684 - val_loss: 0.3958 - val_auc: 0.8898\n",
      "Epoch 103/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4340 - auc: 0.8693 - val_loss: 0.3883 - val_auc: 0.8936\n",
      "Epoch 104/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4336 - auc: 0.8702 - val_loss: 0.3930 - val_auc: 0.8929\n",
      "Epoch 105/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4381 - auc: 0.8696 - val_loss: 0.3983 - val_auc: 0.8891\n",
      "Epoch 106/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4321 - auc: 0.8719 - val_loss: 0.3929 - val_auc: 0.8899\n",
      "Epoch 107/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4304 - auc: 0.8733 - val_loss: 0.3879 - val_auc: 0.8911\n",
      "Epoch 108/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4343 - auc: 0.8697 - val_loss: 0.3872 - val_auc: 0.8897\n",
      "Epoch 109/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4296 - auc: 0.8717 - val_loss: 0.3849 - val_auc: 0.8897\n",
      "Epoch 110/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4307 - auc: 0.8713 - val_loss: 0.3908 - val_auc: 0.8901\n",
      "Epoch 111/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4288 - auc: 0.8726 - val_loss: 0.3863 - val_auc: 0.8956\n",
      "Epoch 112/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4299 - auc: 0.8689 - val_loss: 0.3815 - val_auc: 0.8950\n",
      "Epoch 113/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4278 - auc: 0.8735 - val_loss: 0.3834 - val_auc: 0.8937\n",
      "Epoch 114/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4307 - auc: 0.8705 - val_loss: 0.3973 - val_auc: 0.8853\n",
      "Epoch 115/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4348 - auc: 0.8703 - val_loss: 0.3772 - val_auc: 0.8935\n",
      "Epoch 116/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4296 - auc: 0.8711 - val_loss: 0.3834 - val_auc: 0.8904\n",
      "Epoch 117/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4262 - auc: 0.8729 - val_loss: 0.3826 - val_auc: 0.8924\n",
      "Epoch 118/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4267 - auc: 0.8725 - val_loss: 0.3907 - val_auc: 0.8904\n",
      "Epoch 119/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4240 - auc: 0.8744 - val_loss: 0.3844 - val_auc: 0.8943\n",
      "Epoch 120/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4268 - auc: 0.8732 - val_loss: 0.3766 - val_auc: 0.8944\n",
      "Epoch 121/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4289 - auc: 0.8723 - val_loss: 0.3867 - val_auc: 0.8921\n",
      "Epoch 122/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4234 - auc: 0.8751 - val_loss: 0.3843 - val_auc: 0.8954\n",
      "Epoch 123/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4224 - auc: 0.8738 - val_loss: 0.3770 - val_auc: 0.8953\n",
      "Epoch 124/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4231 - auc: 0.8719 - val_loss: 0.3784 - val_auc: 0.8933\n",
      "Epoch 125/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4218 - auc: 0.8734 - val_loss: 0.3779 - val_auc: 0.8961\n",
      "Epoch 126/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4202 - auc: 0.8744 - val_loss: 0.3791 - val_auc: 0.8955\n",
      "Epoch 127/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4191 - auc: 0.8764 - val_loss: 0.3831 - val_auc: 0.8946\n",
      "Epoch 128/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4219 - auc: 0.8728 - val_loss: 0.3696 - val_auc: 0.8973\n",
      "Epoch 129/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4247 - auc: 0.8722 - val_loss: 0.3827 - val_auc: 0.8950\n",
      "Epoch 130/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4202 - auc: 0.8746 - val_loss: 0.3771 - val_auc: 0.8972\n",
      "Epoch 131/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4178 - auc: 0.8781 - val_loss: 0.3694 - val_auc: 0.8985\n",
      "Epoch 132/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4221 - auc: 0.8727 - val_loss: 0.3757 - val_auc: 0.8954\n",
      "Epoch 133/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4154 - auc: 0.8776 - val_loss: 0.3750 - val_auc: 0.8984\n",
      "Epoch 134/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4182 - auc: 0.8772 - val_loss: 0.3723 - val_auc: 0.9020\n",
      "Epoch 135/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4163 - auc: 0.8774 - val_loss: 0.3772 - val_auc: 0.8975\n",
      "Epoch 136/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4147 - auc: 0.8776 - val_loss: 0.3733 - val_auc: 0.8980\n",
      "Epoch 137/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4141 - auc: 0.8773 - val_loss: 0.3740 - val_auc: 0.8978\n",
      "Epoch 138/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4148 - auc: 0.8773 - val_loss: 0.3729 - val_auc: 0.9001\n",
      "Epoch 139/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4148 - auc: 0.8780 - val_loss: 0.3746 - val_auc: 0.8994\n",
      "Epoch 140/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4109 - auc: 0.8802 - val_loss: 0.3688 - val_auc: 0.9022\n",
      "Epoch 141/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4134 - auc: 0.8801 - val_loss: 0.3732 - val_auc: 0.9014\n",
      "Epoch 142/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4128 - auc: 0.8785 - val_loss: 0.3781 - val_auc: 0.9004\n",
      "Epoch 143/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4131 - auc: 0.8790 - val_loss: 0.3692 - val_auc: 0.9048\n",
      "Epoch 144/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4115 - auc: 0.8802 - val_loss: 0.3779 - val_auc: 0.9038\n",
      "Epoch 145/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4099 - auc: 0.8802 - val_loss: 0.3642 - val_auc: 0.9075\n",
      "Epoch 146/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4098 - auc: 0.8799 - val_loss: 0.3722 - val_auc: 0.9054\n",
      "Epoch 147/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4138 - auc: 0.8801 - val_loss: 0.3644 - val_auc: 0.9073\n",
      "Epoch 148/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4104 - auc: 0.8791 - val_loss: 0.3736 - val_auc: 0.9055\n",
      "Epoch 149/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4080 - auc: 0.8813 - val_loss: 0.3685 - val_auc: 0.9069\n",
      "Epoch 150/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4064 - auc: 0.8822 - val_loss: 0.3672 - val_auc: 0.9072\n",
      "Epoch 151/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4111 - auc: 0.8798 - val_loss: 0.3639 - val_auc: 0.9088\n",
      "Epoch 152/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4106 - auc: 0.8791 - val_loss: 0.3645 - val_auc: 0.9071\n",
      "Epoch 153/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4085 - auc: 0.8807 - val_loss: 0.3609 - val_auc: 0.9101\n",
      "Epoch 154/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4058 - auc: 0.8817 - val_loss: 0.3676 - val_auc: 0.9090\n",
      "Epoch 155/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4077 - auc: 0.8810 - val_loss: 0.3716 - val_auc: 0.9063\n",
      "Epoch 156/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4099 - auc: 0.8802 - val_loss: 0.3598 - val_auc: 0.9118\n",
      "Epoch 157/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4183 - auc: 0.8773 - val_loss: 0.3886 - val_auc: 0.9005\n",
      "Epoch 158/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4051 - auc: 0.8831 - val_loss: 0.3548 - val_auc: 0.9115\n",
      "Epoch 159/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4109 - auc: 0.8836 - val_loss: 0.3599 - val_auc: 0.9099\n",
      "Epoch 160/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4095 - auc: 0.8796 - val_loss: 0.3778 - val_auc: 0.9052\n",
      "Epoch 161/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4089 - auc: 0.8814 - val_loss: 0.3574 - val_auc: 0.9124\n",
      "Epoch 162/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4010 - auc: 0.8852 - val_loss: 0.3709 - val_auc: 0.9090\n",
      "Epoch 163/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4029 - auc: 0.8829 - val_loss: 0.3612 - val_auc: 0.9125\n",
      "Epoch 164/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.4008 - auc: 0.8855 - val_loss: 0.3587 - val_auc: 0.9123\n",
      "Epoch 165/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4068 - auc: 0.8815 - val_loss: 0.3684 - val_auc: 0.9092\n",
      "Epoch 166/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4014 - auc: 0.8853 - val_loss: 0.3589 - val_auc: 0.9132\n",
      "Epoch 167/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4017 - auc: 0.8842 - val_loss: 0.3569 - val_auc: 0.9127\n",
      "Epoch 168/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3987 - auc: 0.8859 - val_loss: 0.3641 - val_auc: 0.9114\n",
      "Epoch 169/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4115 - auc: 0.8799 - val_loss: 0.3621 - val_auc: 0.9139\n",
      "Epoch 170/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4150 - auc: 0.8794 - val_loss: 0.3724 - val_auc: 0.9094\n",
      "Epoch 171/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4019 - auc: 0.8844 - val_loss: 0.3597 - val_auc: 0.9162\n",
      "Epoch 172/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3994 - auc: 0.8844 - val_loss: 0.3589 - val_auc: 0.9109\n",
      "Epoch 173/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3982 - auc: 0.8849 - val_loss: 0.3563 - val_auc: 0.9145\n",
      "Epoch 174/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3968 - auc: 0.8886 - val_loss: 0.3628 - val_auc: 0.9135\n",
      "Epoch 175/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3982 - auc: 0.8871 - val_loss: 0.3603 - val_auc: 0.9155\n",
      "Epoch 176/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4725 - auc: 0.8655 - val_loss: 0.3503 - val_auc: 0.9142\n",
      "Epoch 177/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4243 - auc: 0.8753 - val_loss: 0.3692 - val_auc: 0.9098\n",
      "Epoch 178/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4080 - auc: 0.8820 - val_loss: 0.3721 - val_auc: 0.9057\n",
      "Epoch 179/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.4025 - auc: 0.8825 - val_loss: 0.3607 - val_auc: 0.9132\n",
      "Epoch 180/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3997 - auc: 0.8855 - val_loss: 0.3539 - val_auc: 0.9158\n",
      "Epoch 181/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3993 - auc: 0.8868 - val_loss: 0.3576 - val_auc: 0.9132\n",
      "Epoch 182/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3996 - auc: 0.8845 - val_loss: 0.3583 - val_auc: 0.9131\n",
      "Epoch 183/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3960 - auc: 0.8870 - val_loss: 0.3537 - val_auc: 0.9171\n",
      "Epoch 184/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3946 - auc: 0.8881 - val_loss: 0.3592 - val_auc: 0.9175\n",
      "Epoch 185/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3953 - auc: 0.8874 - val_loss: 0.3568 - val_auc: 0.9145\n",
      "Epoch 186/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3930 - auc: 0.8881 - val_loss: 0.3539 - val_auc: 0.9177\n",
      "Epoch 187/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3917 - auc: 0.8904 - val_loss: 0.3548 - val_auc: 0.9160\n",
      "Epoch 188/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3938 - auc: 0.8874 - val_loss: 0.3560 - val_auc: 0.9154\n",
      "Epoch 189/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3921 - auc: 0.8886 - val_loss: 0.3486 - val_auc: 0.9171\n",
      "Epoch 190/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3967 - auc: 0.8859 - val_loss: 0.3735 - val_auc: 0.9073\n",
      "Epoch 191/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3963 - auc: 0.8868 - val_loss: 0.3575 - val_auc: 0.9181\n",
      "Epoch 192/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3968 - auc: 0.8878 - val_loss: 0.3490 - val_auc: 0.9202\n",
      "Epoch 193/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3939 - auc: 0.8879 - val_loss: 0.3570 - val_auc: 0.9170\n",
      "Epoch 194/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3975 - auc: 0.8859 - val_loss: 0.3569 - val_auc: 0.9186\n",
      "Epoch 195/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3943 - auc: 0.8900 - val_loss: 0.3454 - val_auc: 0.9209\n",
      "Epoch 196/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3929 - auc: 0.8885 - val_loss: 0.3477 - val_auc: 0.9213\n",
      "Epoch 197/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3903 - auc: 0.8898 - val_loss: 0.3596 - val_auc: 0.9175\n",
      "Epoch 198/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3898 - auc: 0.8911 - val_loss: 0.3553 - val_auc: 0.9199\n",
      "Epoch 199/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3907 - auc: 0.8914 - val_loss: 0.3476 - val_auc: 0.9236\n",
      "Epoch 200/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3895 - auc: 0.8909 - val_loss: 0.3550 - val_auc: 0.9204\n",
      "Epoch 201/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3891 - auc: 0.8909 - val_loss: 0.3589 - val_auc: 0.9170\n",
      "Epoch 202/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3892 - auc: 0.8918 - val_loss: 0.3539 - val_auc: 0.9194\n",
      "Epoch 203/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3877 - auc: 0.8928 - val_loss: 0.3551 - val_auc: 0.9201\n",
      "Epoch 204/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3894 - auc: 0.8929 - val_loss: 0.3483 - val_auc: 0.9219\n",
      "Epoch 205/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3865 - auc: 0.8927 - val_loss: 0.3600 - val_auc: 0.9176\n",
      "Epoch 206/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3873 - auc: 0.8935 - val_loss: 0.3462 - val_auc: 0.9236\n",
      "Epoch 207/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3886 - auc: 0.8915 - val_loss: 0.3495 - val_auc: 0.9228\n",
      "Epoch 208/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3872 - auc: 0.8924 - val_loss: 0.3548 - val_auc: 0.9199\n",
      "Epoch 209/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3854 - auc: 0.8939 - val_loss: 0.3506 - val_auc: 0.9216\n",
      "Epoch 210/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3875 - auc: 0.8919 - val_loss: 0.3527 - val_auc: 0.9202\n",
      "Epoch 211/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3905 - auc: 0.8909 - val_loss: 0.3514 - val_auc: 0.9209\n",
      "Epoch 212/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3885 - auc: 0.8918 - val_loss: 0.3468 - val_auc: 0.9226\n",
      "Epoch 213/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3857 - auc: 0.8930 - val_loss: 0.3551 - val_auc: 0.9200\n",
      "Epoch 214/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3897 - auc: 0.8912 - val_loss: 0.3509 - val_auc: 0.9237\n",
      "Epoch 215/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3888 - auc: 0.8900 - val_loss: 0.3580 - val_auc: 0.9175\n",
      "Epoch 216/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3838 - auc: 0.8933 - val_loss: 0.3481 - val_auc: 0.9237\n",
      "Epoch 217/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3880 - auc: 0.8916 - val_loss: 0.3503 - val_auc: 0.9222\n",
      "Epoch 218/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3849 - auc: 0.8935 - val_loss: 0.3492 - val_auc: 0.9227\n",
      "Epoch 219/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3878 - auc: 0.8918 - val_loss: 0.3517 - val_auc: 0.9217\n",
      "Epoch 220/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3868 - auc: 0.8912 - val_loss: 0.3456 - val_auc: 0.9250\n",
      "Epoch 221/300\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 0.3876 - auc: 0.8908 - val_loss: 0.3696 - val_auc: 0.9114\n",
      "Epoch 222/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3840 - auc: 0.8946 - val_loss: 0.3466 - val_auc: 0.9239\n",
      "Epoch 223/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3845 - auc: 0.8937 - val_loss: 0.3620 - val_auc: 0.9178\n",
      "Epoch 224/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3880 - auc: 0.8910 - val_loss: 0.3475 - val_auc: 0.9252\n",
      "Epoch 225/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3852 - auc: 0.8925 - val_loss: 0.3555 - val_auc: 0.9220\n",
      "Epoch 226/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3886 - auc: 0.8918 - val_loss: 0.3457 - val_auc: 0.9243\n",
      "Epoch 227/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3844 - auc: 0.8947 - val_loss: 0.3522 - val_auc: 0.9243\n",
      "Epoch 228/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3851 - auc: 0.8936 - val_loss: 0.3475 - val_auc: 0.9251\n",
      "Epoch 229/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3826 - auc: 0.8952 - val_loss: 0.3515 - val_auc: 0.9230\n",
      "Epoch 230/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3843 - auc: 0.8941 - val_loss: 0.3532 - val_auc: 0.9236\n",
      "Epoch 231/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3953 - auc: 0.8913 - val_loss: 0.3518 - val_auc: 0.9245\n",
      "Epoch 232/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3995 - auc: 0.8834 - val_loss: 0.3646 - val_auc: 0.9185\n",
      "Epoch 233/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4149 - auc: 0.8828 - val_loss: 0.3470 - val_auc: 0.9262\n",
      "Epoch 234/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3842 - auc: 0.8948 - val_loss: 0.3567 - val_auc: 0.9189\n",
      "Epoch 235/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3823 - auc: 0.8957 - val_loss: 0.3529 - val_auc: 0.9240\n",
      "Epoch 236/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3857 - auc: 0.8936 - val_loss: 0.3533 - val_auc: 0.9251\n",
      "Epoch 237/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3826 - auc: 0.8954 - val_loss: 0.3491 - val_auc: 0.9249\n",
      "Epoch 238/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3813 - auc: 0.8954 - val_loss: 0.3418 - val_auc: 0.9253\n",
      "Epoch 239/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3824 - auc: 0.8958 - val_loss: 0.3452 - val_auc: 0.9256\n",
      "Epoch 240/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3823 - auc: 0.8965 - val_loss: 0.3573 - val_auc: 0.9228\n",
      "Epoch 241/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3801 - auc: 0.8959 - val_loss: 0.3419 - val_auc: 0.9249\n",
      "Epoch 242/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3815 - auc: 0.8963 - val_loss: 0.3481 - val_auc: 0.9247\n",
      "Epoch 243/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3816 - auc: 0.8949 - val_loss: 0.3507 - val_auc: 0.9240\n",
      "Epoch 244/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3827 - auc: 0.8947 - val_loss: 0.3488 - val_auc: 0.9259\n",
      "Epoch 245/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3915 - auc: 0.8907 - val_loss: 0.3490 - val_auc: 0.9252\n",
      "Epoch 246/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3888 - auc: 0.8928 - val_loss: 0.3415 - val_auc: 0.9275\n",
      "Epoch 247/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3816 - auc: 0.8949 - val_loss: 0.3535 - val_auc: 0.9207\n",
      "Epoch 248/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3860 - auc: 0.8913 - val_loss: 0.3535 - val_auc: 0.9239\n",
      "Epoch 249/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3886 - auc: 0.8926 - val_loss: 0.3403 - val_auc: 0.9262\n",
      "Epoch 250/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3865 - auc: 0.8931 - val_loss: 0.3488 - val_auc: 0.9223\n",
      "Epoch 251/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3843 - auc: 0.8946 - val_loss: 0.3432 - val_auc: 0.9251\n",
      "Epoch 252/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3853 - auc: 0.8944 - val_loss: 0.3507 - val_auc: 0.9204\n",
      "Epoch 253/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3919 - auc: 0.8885 - val_loss: 0.3605 - val_auc: 0.9185\n",
      "Epoch 254/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3834 - auc: 0.8961 - val_loss: 0.3458 - val_auc: 0.9257\n",
      "Epoch 255/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3838 - auc: 0.8974 - val_loss: 0.3505 - val_auc: 0.9262\n",
      "Epoch 256/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3829 - auc: 0.8962 - val_loss: 0.3495 - val_auc: 0.9262\n",
      "Epoch 257/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3784 - auc: 0.8978 - val_loss: 0.3487 - val_auc: 0.9253\n",
      "Epoch 258/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3788 - auc: 0.8968 - val_loss: 0.3429 - val_auc: 0.9266\n",
      "Epoch 259/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3780 - auc: 0.8960 - val_loss: 0.3524 - val_auc: 0.9231\n",
      "Epoch 260/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3793 - auc: 0.8983 - val_loss: 0.3510 - val_auc: 0.9243\n",
      "Epoch 261/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3790 - auc: 0.8964 - val_loss: 0.3411 - val_auc: 0.9284\n",
      "Epoch 262/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3794 - auc: 0.8944 - val_loss: 0.3570 - val_auc: 0.9200\n",
      "Epoch 263/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3807 - auc: 0.8955 - val_loss: 0.3454 - val_auc: 0.9247\n",
      "Epoch 264/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3783 - auc: 0.8967 - val_loss: 0.3425 - val_auc: 0.9272\n",
      "Epoch 265/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3772 - auc: 0.8974 - val_loss: 0.3423 - val_auc: 0.9281\n",
      "Epoch 266/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3808 - auc: 0.8952 - val_loss: 0.3462 - val_auc: 0.9268\n",
      "Epoch 267/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3794 - auc: 0.8951 - val_loss: 0.3475 - val_auc: 0.9240\n",
      "Epoch 268/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3779 - auc: 0.8979 - val_loss: 0.3534 - val_auc: 0.9248\n",
      "Epoch 269/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3771 - auc: 0.8977 - val_loss: 0.3404 - val_auc: 0.9263\n",
      "Epoch 270/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3792 - auc: 0.8967 - val_loss: 0.3464 - val_auc: 0.9268\n",
      "Epoch 271/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3759 - auc: 0.8985 - val_loss: 0.3487 - val_auc: 0.9251\n",
      "Epoch 272/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3797 - auc: 0.8972 - val_loss: 0.3463 - val_auc: 0.9243\n",
      "Epoch 273/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3791 - auc: 0.8975 - val_loss: 0.3510 - val_auc: 0.9257\n",
      "Epoch 274/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3832 - auc: 0.8951 - val_loss: 0.3439 - val_auc: 0.9278\n",
      "Epoch 275/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3870 - auc: 0.8932 - val_loss: 0.3548 - val_auc: 0.9243\n",
      "Epoch 276/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3824 - auc: 0.8965 - val_loss: 0.3427 - val_auc: 0.9277\n",
      "Epoch 277/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3836 - auc: 0.8965 - val_loss: 0.3459 - val_auc: 0.9269\n",
      "Epoch 278/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3795 - auc: 0.8973 - val_loss: 0.3417 - val_auc: 0.9288\n",
      "Epoch 279/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3764 - auc: 0.8986 - val_loss: 0.3582 - val_auc: 0.9211\n",
      "Epoch 280/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3792 - auc: 0.8970 - val_loss: 0.3461 - val_auc: 0.9260\n",
      "Epoch 281/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3758 - auc: 0.8987 - val_loss: 0.3482 - val_auc: 0.9268\n",
      "Epoch 282/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3750 - auc: 0.8989 - val_loss: 0.3510 - val_auc: 0.9226\n",
      "Epoch 283/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3766 - auc: 0.8994 - val_loss: 0.3418 - val_auc: 0.9276\n",
      "Epoch 284/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3774 - auc: 0.8977 - val_loss: 0.3431 - val_auc: 0.9276\n",
      "Epoch 285/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3763 - auc: 0.9011 - val_loss: 0.3471 - val_auc: 0.9260\n",
      "Epoch 286/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3753 - auc: 0.8992 - val_loss: 0.3434 - val_auc: 0.9270\n",
      "Epoch 287/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3747 - auc: 0.8986 - val_loss: 0.3554 - val_auc: 0.9218\n",
      "Epoch 288/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3779 - auc: 0.8964 - val_loss: 0.3467 - val_auc: 0.9276\n",
      "Epoch 289/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3767 - auc: 0.8967 - val_loss: 0.3437 - val_auc: 0.9282\n",
      "Epoch 290/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3749 - auc: 0.9010 - val_loss: 0.3447 - val_auc: 0.9275\n",
      "Epoch 291/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3731 - auc: 0.9004 - val_loss: 0.3459 - val_auc: 0.9268\n",
      "Epoch 292/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3721 - auc: 0.9011 - val_loss: 0.3455 - val_auc: 0.9269\n",
      "Epoch 293/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3737 - auc: 0.9001 - val_loss: 0.3425 - val_auc: 0.9281\n",
      "Epoch 294/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3748 - auc: 0.8991 - val_loss: 0.3428 - val_auc: 0.9269\n",
      "Epoch 295/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3795 - auc: 0.8978 - val_loss: 0.3431 - val_auc: 0.9276\n",
      "Epoch 296/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3757 - auc: 0.8996 - val_loss: 0.3484 - val_auc: 0.9256\n",
      "Epoch 297/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3790 - auc: 0.8943 - val_loss: 0.3527 - val_auc: 0.9255\n",
      "Epoch 298/300\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3727 - auc: 0.9005 - val_loss: 0.3369 - val_auc: 0.9274\n",
      "Epoch 299/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3734 - auc: 0.9012 - val_loss: 0.3398 - val_auc: 0.9265\n",
      "Epoch 300/300\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.3780 - auc: 0.8986 - val_loss: 0.3367 - val_auc: 0.9284\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "\n",
    "#\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=300, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "tracked-garage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.callbacks.History"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "metric-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss \n",
    "# History API\n",
    "# history.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "compact-filename",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9f52d06cd76a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model/tf_save_weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#load_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# model.save()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weight/tf_save_model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "model.save_weights('./model/tf_save_weight', save_format='tf') #load_model\n",
    "# model.save()\n",
    "model.save('./weight/tf_save_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "simplified-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "waiting-testimony",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('./weight/tf_save_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "advance-windows",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.engine.sequential.Sequential"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "psychological-contract",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "seasonal-button",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: ./weight/tf_save_model/{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ddef24d54403>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weight/tf_save_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu2.2/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    187\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m       \u001b[0mloader_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu2.2/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[0;34m(export_dir)\u001b[0m\n\u001b[1;32m    111\u001b[0m                   (export_dir,\n\u001b[1;32m    112\u001b[0m                    \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSAVED_MODEL_FILENAME_PBTXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                    constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: SavedModel file does not exist at: ./weight/tf_save_model/{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "model = models.load_model('./weight/tf_save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-complexity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
